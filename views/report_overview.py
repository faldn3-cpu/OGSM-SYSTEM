import streamlit as st
import pandas as pd
from datetime import date, datetime, timedelta
import gspread
import time
from gspread.exceptions import APIError
import logging

# === è¨­å®š:ç³»çµ±åˆ†é é»‘åå–® ===
SYSTEM_SHEETS = [
    "DATA", "ç¶“éŠ·åƒ¹(ç¸½)", "æ•´å¥—æ­é…", "åƒæ•¸è¨­å®š", "ç¸½è¡¨", 
    "æº«æ§å™¨", "é›·å°„", "SENSOR", "æ¸›é€Ÿæ©Ÿ", "è®Šé »å™¨", "ä¼ºæœ", 
    "PLC", "äººæ©Ÿ", "è»Ÿé«”", "Robot", "é…ä»¶", "ç«¯å­è‡º",
    "Users", "Logs", "Sessions"
]

# === è¨­å®š:ç›´è³£å…¨å“¡åå–® ===
DIRECT_SALES_NAMES = [
    "æ›¾ä»å›", "æº«é”ä»", "æ¥Šå®¶è±ª", "èŠå¯Œä¸", "è¬ç‘é¨", "ä½•å®›èŒ¹", "å¼µæ›¸å‰"
]

# === è¨­å®š:ç¶“éŠ·å…¨å“¡åå–® ===
DISTRIBUTOR_SALES_NAMES = [
    "å¼µä½•é”", "å‘¨æŸç¿°", "è‘‰ä»è±ª"
]

# === è¨­å®š:ç‰¹æ®Šç¾¤çµ„é¸é …åç¨± ===
OPT_ALL = "(1) ğŸŸ¢ å…¨å“¡é¸å–"
OPT_DIRECT = "(2) ğŸ”µ ç›´è³£å…¨å“¡"
OPT_DIST = "(3) ğŸŸ  ç¶“éŠ·å…¨å“¡"
SPECIAL_OPTS = [OPT_ALL, OPT_DIRECT, OPT_DIST]

# === ã€ä¿®å¾©ã€‘CSV Injection é˜²è­· ===
def sanitize_csv_field(value):
    """æ¸…ç† CSV æ¬„ä½ä»¥é˜²æ³¨å…¥æ”»æ“Š"""
    if not isinstance(value, str):
        return value
    
    dangerous_chars = ['=', '+', '-', '@', '\t', '\r']
    if value and value[0] in dangerous_chars:
        return "'" + value
    
    return value

# === ã€ä¿®å¾©ã€‘åŠ å…¥æ™ºæ…§å»¶é²ç­–ç•¥ ===
class APIRateLimiter:
    """API é€Ÿç‡é™åˆ¶å™¨ (æŒ‡æ•¸é€€é¿)"""
    def __init__(self):
        self.request_times = []
        self.base_delay = 0.5  # åŸºç¤å»¶é² 0.5 ç§’
        self.max_delay = 10    # æœ€å¤§å»¶é² 10 ç§’
        self.current_delay = self.base_delay
        
    def wait(self):
        """æ™ºæ…§ç­‰å¾… (æ ¹æ“šè¿‘æœŸ API å‘¼å«é »ç‡å‹•æ…‹èª¿æ•´)"""
        now = time.time()
        # æ¸…é™¤ 60 ç§’å‰çš„è¨˜éŒ„
        self.request_times = [t for t in self.request_times if now - t < 60]
        
        # å¦‚æœæœ€è¿‘ 1 åˆ†é˜å…§å‘¼å«è¶…é 50 æ¬¡ï¼Œå¢åŠ å»¶é²
        if len(self.request_times) > 50:
            self.current_delay = min(self.current_delay * 1.5, self.max_delay)
        else:
            # é€æ¼¸é™ä½å»¶é²
            self.current_delay = max(self.current_delay * 0.9, self.base_delay)
        
        time.sleep(self.current_delay)
        self.request_times.append(now)
    
    def handle_error(self, attempt):
        """è™•ç† 429 éŒ¯èª¤çš„ç­‰å¾…æ™‚é–“ (æŒ‡æ•¸é€€é¿)"""
        wait_time = min(2 ** attempt * 2, 30)  # 2ç§’, 4ç§’, 8ç§’...æœ€å¤š30ç§’
        return wait_time

rate_limiter = APIRateLimiter()

def load_data_from_sheet(ws, start_date, end_date):
    """è®€å–è³‡æ–™ä¸¦æ¸…æ´— (åŠ å…¥é‡è©¦æ©Ÿåˆ¶)"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # ã€ä¿®å¾©ã€‘ä½¿ç”¨æ™ºæ…§å»¶é²
            if attempt > 0:
                wait_time = rate_limiter.handle_error(attempt)
                time.sleep(wait_time)
            
            data = ws.get_all_records()
            ui_columns = ["æ—¥æœŸ", "æ˜ŸæœŸ", "å®¢æˆ¶åç¨±", "å®¢æˆ¶åˆ†é¡", "å·¥ä½œå…§å®¹", "å¯¦éš›è¡Œç¨‹", "æœ€å¾Œæ›´æ–°æ™‚é–“"]
            
            if not data:
                return pd.DataFrame(columns=ui_columns)
            
            df = pd.DataFrame(data)

            if "é …æ¬¡" in df.columns:
                df = df.drop(columns=["é …æ¬¡"])
            
            for col in ui_columns:
                if col not in df.columns:
                    df[col] = ""

            df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce').dt.date
            df = df.dropna(subset=["æ—¥æœŸ"]) 

            mask = (df["æ—¥æœŸ"] >= start_date) & (df["æ—¥æœŸ"] <= end_date)
            filtered_df = df.loc[mask].copy()
            
            filtered_df = filtered_df.sort_values(by=["æ—¥æœŸ"], ascending=False)
            return filtered_df[ui_columns]
        
        except APIError as e:
            if "429" in str(e) or "Quota exceeded" in str(e):
                if attempt < max_retries - 1:
                    wait_time = rate_limiter.handle_error(attempt + 1)
                    logging.warning(f"API 429 error, waiting {wait_time}s before retry")
                    continue
                else:
                    logging.error(f"API quota exceeded after {max_retries} retries")
                    raise
            else:
                logging.error(f"API error: {e}")
                raise
        except Exception as e:
            logging.error(f"Failed to load data from sheet: {e}")
            return pd.DataFrame()
    
    return pd.DataFrame()

def get_all_sales_names(all_ws_objects):
    """ç›´æ¥å¾å·²æŠ“å–çš„ Worksheet ç‰©ä»¶åˆ—è¡¨ä¸­ç¯©é¸åç¨±"""
    sales_names = []
    for ws in all_ws_objects:
        title = ws.title
        if title not in SYSTEM_SHEETS and not title.startswith("æ•´å¥—_") and "ç¶“éŠ·" not in title:
            sales_names.append(title)
    return sales_names

def show(client, db_name, user_email, real_name, is_manager):
    st.title("ğŸ“Š æ—¥å ±ç¸½è¦½èˆ‡åŒ¯å‡º")

    try:
        sh = client.open(db_name)
    except Exception as e:
        st.error(f"æ‰¾ä¸åˆ°è³‡æ–™åº«:{db_name}")
        logging.error(f"Failed to open database: {e}")
        return

    # === 1. æ—¥æœŸé¸æ“‡å™¨ ===
    col1, col2 = st.columns([2, 1])
    with col1:
        today = date.today()
        start_default = today - timedelta(days=today.weekday())
        end_default = today
        
        date_range = st.date_input(
            "ğŸ“… é¸æ“‡æŸ¥è©¢å€é–“", 
            (start_default, end_default),
            key="overview_range_picker"
        )

    if isinstance(date_range, tuple) and len(date_range) == 2:
        start_date, end_date = date_range
    else:
        st.warning("è«‹é¸æ“‡å®Œæ•´çš„èµ·å§‹èˆ‡çµæŸæ—¥æœŸ")
        return

    # === 2. äººå“¡é¸æ“‡ ===
    user_role = "manager" if is_manager else "sales"
    current_user_name = real_name
    target_users = []

    try:
        all_ws_objects = sh.worksheets()
        ws_map = {ws.title: ws for ws in all_ws_objects}
    except Exception as e:
        st.error(f"è®€å–è³‡æ–™åº«çµæ§‹å¤±æ•—: {e}")
        logging.error(f"Failed to load worksheets: {e}")
        return

    if user_role == "manager":
        if "overview_sales_select" not in st.session_state:
            st.session_state.overview_sales_select = []
        if "overview_sales_prev" not in st.session_state:
            st.session_state.overview_sales_prev = st.session_state.overview_sales_select

        all_sales = get_all_sales_names(all_ws_objects)
        
        valid_direct_names = [name for name in DIRECT_SALES_NAMES if name in all_sales]
        valid_dist_names = [name for name in DISTRIBUTOR_SALES_NAMES if name in all_sales]
        
        menu_options = SPECIAL_OPTS + sorted(all_sales)

        def on_selection_change():
            current = st.session_state.overview_sales_select
            previous = st.session_state.overview_sales_prev
            
            added = [item for item in current if item not in previous]
            new_selection = current
            
            if added:
                new_item = added[-1]
                if new_item in SPECIAL_OPTS:
                    new_selection = [new_item]
                else:
                    new_selection = [item for item in current if item not in SPECIAL_OPTS]
            
            st.session_state.overview_sales_select = new_selection
            st.session_state.overview_sales_prev = new_selection

        with col2:
            st.multiselect(
                "ğŸ‘¥ é¸æ“‡æŸ¥çœ‹å°è±¡",
                options=menu_options,
                key="overview_sales_select", 
                on_change=on_selection_change 
            )

        selected_options = st.session_state.overview_sales_select
        
        final_target_set = set()
        if OPT_ALL in selected_options:
            final_target_set.update(all_sales)
        else:
            if OPT_DIRECT in selected_options:
                final_target_set.update(valid_direct_names)
            if OPT_DIST in selected_options:
                final_target_set.update(valid_dist_names)
            
            for opt in selected_options:
                if opt not in SPECIAL_OPTS:
                    final_target_set.add(opt)
        
        target_users = sorted(list(final_target_set))
            
    else:
        with col2:
            st.text_input("ğŸ‘¤ æŸ¥çœ‹å°è±¡", value=current_user_name, disabled=True)
        target_users = [current_user_name]

    if not target_users:
        if user_role == "manager":
            st.info("è«‹é¸æ“‡äººå“¡æˆ–ç¾¤çµ„ (é è¨­ä¸é¡¯ç¤ºï¼Œè«‹æ‰‹å‹•é¸æ“‡)ã€‚")
        else:
            st.error("æ‰¾ä¸åˆ°æ‚¨çš„è³‡æ–™è¡¨ï¼Œè«‹è¯ç¹«ç®¡ç†å“¡ã€‚")
        return

    st.markdown("---")
    
    # === 3. ã€ä¿®å¾©ã€‘è®€å–èˆ‡é¡¯ç¤º (æ™ºæ…§é€Ÿç‡é™åˆ¶ç‰ˆ) ===
    all_data = []
    
    # ã€ä¿®å¾©ã€‘é™åˆ¶æœ€å¤§æŸ¥è©¢äººæ•¸
    MAX_USERS = 30  # é™ä½è‡³ 30 äººä»¥æ¸›å°‘ API å£“åŠ›
    if len(target_users) > MAX_USERS:
        st.error(f"âš ï¸ ä¸€æ¬¡æœ€å¤šæŸ¥è©¢ {MAX_USERS} ä½æ¥­å‹™å“¡ï¼Œè«‹ç¸®å°ç¯„åœ")
        st.info("ğŸ’¡ å»ºè­°ä½¿ç”¨ã€Œç›´è³£å…¨å“¡ã€æˆ–ã€Œç¶“éŠ·å…¨å“¡ã€ç¾¤çµ„ï¼Œæˆ–æ‰‹å‹•é¸æ“‡å°‘æ•¸äººå“¡")
        return
    
    # ã€ä¿®å¾©ã€‘é¡¯ç¤ºé ä¼°æ™‚é–“
    estimated_time = len(target_users) * rate_limiter.current_delay
    st.info(f"â±ï¸ æ­£åœ¨è®€å– {len(target_users)} ä½æ¥­å‹™å“¡è³‡æ–™ (é è¨ˆéœ€æ™‚ {estimated_time:.1f} ç§’)")
    
    with st.spinner(f"å½™æ•´ä¸­... (ä½¿ç”¨æ™ºæ…§é€Ÿç‡é™åˆ¶ä»¥é¿å…è¶…è¼‰)"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        failed_users = []
        
        for idx, user_name in enumerate(target_users):
            status_text.text(f"æ­£åœ¨è®€å–: {user_name} ({idx+1}/{len(target_users)})")
            ws = ws_map.get(user_name)
            
            if ws:
                try:
                    # ã€ä¿®å¾©ã€‘ä½¿ç”¨æ™ºæ…§å»¶é²
                    rate_limiter.wait()
                    
                    df = load_data_from_sheet(ws, start_date, end_date)
                    if not df.empty:
                        df.insert(0, "æ¥­å‹™å“¡", user_name)
                        all_data.append(df)
                
                except APIError as e:
                    if "429" in str(e):
                        failed_users.append(user_name)
                        st.warning(f"âš ï¸ {user_name} è®€å–å¤±æ•— (API è¶…è¼‰)ï¼Œè«‹ç¨å¾Œé‡è©¦")
                        logging.error(f"API 429 for {user_name}")
                    else:
                        failed_users.append(user_name)
                        logging.error(f"API error for {user_name}: {e}")
                
                except Exception as e:
                    failed_users.append(user_name)
                    logging.error(f"Unexpected error loading {user_name}: {e}")
            
            progress_bar.progress((idx + 1) / len(target_users))
        
        status_text.empty()
        progress_bar.empty()
        
        # é¡¯ç¤ºå¤±æ•—åå–®
        if failed_users:
            st.error(f"âŒ ä»¥ä¸‹ {len(failed_users)} ä½æ¥­å‹™å“¡è³‡æ–™è®€å–å¤±æ•—: {', '.join(failed_users)}")
            st.info("ğŸ’¡ å»ºè­°: ç­‰å¾… 1 åˆ†é˜å¾Œé‡æ–°æŸ¥è©¢ï¼Œæˆ–æ¸›å°‘ä¸€æ¬¡æŸ¥è©¢çš„äººæ•¸")

    if not all_data:
        st.info("ğŸ” æ‰€é¸å€é–“å…§ç„¡è³‡æ–™ã€‚")
        return

    final_df = pd.concat(all_data, ignore_index=True)
    
    # çµ±è¨ˆæ‘˜è¦
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆæ‘˜è¦ ({start_date} ~ {end_date})")
    m1, m2, m3 = st.columns(3)
    m1.metric("ç¸½å¡«å¯«ç­†æ•¸", len(final_df))
    m2.metric("åƒèˆ‡æ¥­å‹™äººæ•¸", len(final_df["æ¥­å‹™å“¡"].unique()))
    m3.metric("æ‹œè¨ªå®¢æˆ¶æ•¸", len(final_df["å®¢æˆ¶åç¨±"].unique()))

    # è©³ç´°è¡¨æ ¼
    st.subheader("ğŸ“ è©³ç´°åˆ—è¡¨")
    
    # ã€ä¿®å¾©ã€‘é™åˆ¶é¡¯ç¤ºç­†æ•¸
    MAX_DISPLAY_ROWS = 1000
    if len(final_df) > MAX_DISPLAY_ROWS:
        st.warning(f"âš ï¸ è³‡æ–™éå¤šï¼Œåƒ…é¡¯ç¤ºå‰ {MAX_DISPLAY_ROWS} ç­† (ä¸‹è¼‰ CSV å¯å–å¾—å®Œæ•´è³‡æ–™)")
        display_df = final_df.head(MAX_DISPLAY_ROWS)
    else:
        display_df = final_df
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "æ—¥æœŸ": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD"),
            "æœ€å¾Œæ›´æ–°æ™‚é–“": st.column_config.TextColumn("æ›´æ–°æ™‚é–“", width="small")
        }
    )

    # ã€ä¿®å¾©ã€‘åŒ¯å‡º CSV
    fname = f"æ¥­å‹™æ—¥å ±å½™æ•´_{start_date}_{end_date}.csv"
    
    export_df = final_df.copy()
    export_df = export_df.applymap(sanitize_csv_field)
    
    csv = export_df.to_csv(index=False).encode('utf-8-sig')
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰ CSV å ±è¡¨",
        data=csv,
        file_name=fname,
        mime="text/csv",
        type="primary"
    )
    st.caption("âš ï¸ ä¸‹è¼‰å¾Œè«‹åœ¨å—ä¿¡ä»»çš„ç’°å¢ƒä¸­é–‹å•Ÿæª”æ¡ˆ")