import streamlit as st
import pandas as pd
from datetime import date, datetime, timedelta
import gspread
import time
from gspread.exceptions import APIError, SpreadsheetNotFound
import logging

# === è¨­å®š:ç³»çµ±åˆ†é é»‘åå–® ===
SYSTEM_SHEETS = [
    "DATA", "ç¶“éŠ·åƒ¹(ç¸½)", "æ•´å¥—æ­é…", "åƒæ•¸è¨­å®š", "ç¸½è¡¨", 
    "æº«æ§å™¨", "é›·å°„", "SENSOR", "æ¸›é€Ÿæ©Ÿ", "è®Šé »å™¨", "ä¼ºæœ", 
    "PLC", "äººæ©Ÿ", "è»Ÿé«”", "Robot", "é…ä»¶", "ç«¯å­è‡º",
    "Users", "Logs", "Sessions"
]

# === è¨­å®š:ç›´è³£å…¨å“¡åå–® ===
DIRECT_SALES_NAMES = [
    "æ›¾ä»å›", "æº«é”ä»", "æ¥Šå®¶è±ª", "èŠå¯Œä¸", "è¬ç‘é¨", "ä½•å®›èŒ¹", "å¼µæ›¸å‰"
]

# === è¨­å®š:ç¶“éŠ·å…¨å“¡åå–® ===
DISTRIBUTOR_SALES_NAMES = [
    "å¼µä½•é”", "å‘¨æŸç¿°", "è‘‰ä»è±ª"
]

# === è¨­å®š:ç‰¹æ®Šç¾¤çµ„é¸é …åç¨± ===
OPT_ALL = "(1) ğŸŸ¢ å…¨å“¡é¸å–"
OPT_DIRECT = "(2) ğŸ”µ ç›´è³£å…¨å“¡"
OPT_DIST = "(3) ğŸŸ  ç¶“éŠ·å…¨å“¡"
SPECIAL_OPTS = [OPT_ALL, OPT_DIRECT, OPT_DIST]

# === è³‡æ–™åº«é€£ç·š (ç§»é™¤å¿«å–ä»¥ç¢ºä¿ç©©å®šæ€§) ===
def get_spreadsheet_with_retry(client, db_name, max_retries=3):
    """
    ä½¿ç”¨é‡è©¦æ©Ÿåˆ¶é–‹å•Ÿ Google Sheets
    """
    for attempt in range(max_retries):
        try:
            sh = client.open(db_name)
            return sh
        except SpreadsheetNotFound:
            logging.error(f"Spreadsheet not found: {db_name}")
            raise
        except APIError as e:
            if "429" in str(e) or "Quota exceeded" in str(e):
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    time.sleep(wait_time)
                    continue
                else:
                    raise
            else:
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                else:
                    raise
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 1.5
                time.sleep(wait_time)
                continue
            else:
                raise
    return None

# === å–å¾—å·¥ä½œè¡¨åˆ—è¡¨ (ç§»é™¤å¿«å–ä»¥é¿å…ç‰©ä»¶åºåˆ—åŒ–éŒ¯èª¤) ===
def get_worksheets_retry(spreadsheet):
    """
    å–å¾—å·¥ä½œè¡¨åˆ—è¡¨
    """
    try:
        worksheets = spreadsheet.worksheets()
        return {ws.title: ws for ws in worksheets}
    except Exception as e:
        logging.error(f"Failed to get worksheets: {e}")
        return {}

# === CSV Injection é˜²è­· ===
def sanitize_csv_field(value):
    """æ¸…ç† CSV æ¬„ä½ä»¥é˜²æ³¨å…¥æ”»æ“Š"""
    if not isinstance(value, str):
        return value
    
    dangerous_chars = ['=', '+', '-', '@', '\t', '\r']
    if value and value[0] in dangerous_chars:
        return "'" + value
    
    return value

# === æ™ºæ…§å»¶é²ç­–ç•¥ ===
class APIRateLimiter:
    """API é€Ÿç‡é™åˆ¶å™¨ (æŒ‡æ•¸é€€é¿)"""
    def __init__(self):
        self.request_times = []
        self.base_delay = 0.5
        self.max_delay = 10
        self.current_delay = self.base_delay
        
    def wait(self):
        """æ™ºæ…§ç­‰å¾…"""
        now = time.time()
        self.request_times = [t for t in self.request_times if now - t < 60]
        
        if len(self.request_times) > 50:
            self.current_delay = min(self.current_delay * 1.5, self.max_delay)
        else:
            self.current_delay = max(self.current_delay * 0.9, self.base_delay)
        
        time.sleep(self.current_delay)
        self.request_times.append(now)
    
    def handle_error(self, attempt):
        """è™•ç† 429 éŒ¯èª¤çš„ç­‰å¾…æ™‚é–“"""
        wait_time = min(2 ** attempt * 2, 30)
        return wait_time

rate_limiter = APIRateLimiter()

def load_data_from_sheet(ws, start_date, end_date):
    """è®€å–è³‡æ–™ä¸¦æ¸…æ´— (åŠ å…¥é‡è©¦æ©Ÿåˆ¶)"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                wait_time = rate_limiter.handle_error(attempt)
                time.sleep(wait_time)
            
            data = ws.get_all_records()
            ui_columns = ["æ—¥æœŸ", "æ˜ŸæœŸ", "å®¢æˆ¶åç¨±", "å®¢æˆ¶åˆ†é¡", "å·¥ä½œå…§å®¹", "å¯¦éš›è¡Œç¨‹", "æœ€å¾Œæ›´æ–°æ™‚é–“"]
            
            if not data:
                return pd.DataFrame(columns=ui_columns)
            
            df = pd.DataFrame(data)

            if "é …æ¬¡" in df.columns:
                df = df.drop(columns=["é …æ¬¡"])
            
            for col in ui_columns:
                if col not in df.columns:
                    df[col] = ""

            df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce').dt.date
            df = df.dropna(subset=["æ—¥æœŸ"]) 

            mask = (df["æ—¥æœŸ"] >= start_date) & (df["æ—¥æœŸ"] <= end_date)
            filtered_df = df.loc[mask].copy()
            
            filtered_df = filtered_df.sort_values(by=["æ—¥æœŸ"], ascending=False)
            return filtered_df[ui_columns]
        
        except APIError as e:
            if "429" in str(e) or "Quota exceeded" in str(e):
                if attempt < max_retries - 1:
                    wait_time = rate_limiter.handle_error(attempt + 1)
                    continue
                else:
                    logging.error(f"API quota exceeded after {max_retries} retries")
                    raise
            else:
                logging.error(f"API error: {e}")
                raise
        except Exception as e:
            logging.error(f"Failed to load data from sheet: {e}")
            return pd.DataFrame()
    
    return pd.DataFrame()

def get_all_sales_names(ws_map):
    """å¾å·¥ä½œè¡¨å­—å…¸ä¸­ç¯©é¸æ¥­å‹™å“¡åç¨±"""
    sales_names = []
    for title in ws_map.keys():
        if title not in SYSTEM_SHEETS and not title.startswith("æ•´å¥—_") and "ç¶“éŠ·" not in title:
            sales_names.append(title)
    return sales_names

def show(client, db_name, user_email, real_name, is_manager):
    st.title("ğŸ“Š æ—¥å ±ç¸½è¦½èˆ‡åŒ¯å‡º")

    # === é€£ç·šè³‡æ–™åº« ===
    try:
        with st.spinner("æ­£åœ¨é€£ç·šè³‡æ–™åº«..."):
            sh = get_spreadsheet_with_retry(client, db_name)
            if not sh:
                st.error(f"âŒ ç„¡æ³•é–‹å•Ÿè³‡æ–™åº«: {db_name}")
                return
    except SpreadsheetNotFound:
        st.error(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™åº«: {db_name}")
        st.info("ğŸ’¡ è«‹ç¢ºèª Google Sheet åç¨±æ˜¯å¦æ­£ç¢ºï¼Œä¸¦å·²å…±ç”¨çµ¦ Service Account")
        return
    except Exception as e:
        st.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        st.info("ğŸ’¡ å¦‚æœæ˜¯ API Error 403ï¼Œä»£è¡¨æ²’æœ‰æ¬Šé™ã€‚")
        return

    # === 1. æ—¥æœŸé¸æ“‡å™¨ ===
    col1, col2 = st.columns([2, 1])
    with col1:
        today = date.today()
        start_default = today - timedelta(days=today.weekday())
        end_default = today
        
        date_range = st.date_input(
            "ğŸ“… é¸æ“‡æŸ¥è©¢å€é–“", 
            (start_default, end_default),
            key="overview_range_picker"
        )

    # ã€èª¿æ•´é †åºã€‘å…ˆè™•ç†äººå“¡é¸æ“‡ï¼Œç¢ºä¿ UI è¢«æ¸²æŸ“ï¼Œé¿å… key è¢«æ¸…é™¤
    # === 2. äººå“¡é¸æ“‡ ===
    user_role = "manager" if is_manager else "sales"
    current_user_name = real_name
    target_users = []

    # === è®€å–å·¥ä½œè¡¨åˆ—è¡¨ ===
    try:
        with st.spinner("æ­£åœ¨è®€å–å·¥ä½œè¡¨åˆ—è¡¨..."):
            ws_map = get_worksheets_retry(sh)
            if not ws_map:
                st.error("âŒ ç„¡æ³•è®€å–å·¥ä½œè¡¨åˆ—è¡¨ (å¯èƒ½æ˜¯ç©ºçš„æˆ–æ¬Šé™ä¸è¶³)")
                return
    except Exception as e:
        st.error(f"âŒ è®€å–è³‡æ–™åº«çµæ§‹å¤±æ•—: {e}")
        return

    if user_role == "manager":
        if "overview_sales_select" not in st.session_state:
            st.session_state.overview_sales_select = []
        if "overview_sales_prev" not in st.session_state:
            st.session_state.overview_sales_prev = st.session_state.overview_sales_select

        all_sales = get_all_sales_names(ws_map)
        
        valid_direct_names = [name for name in DIRECT_SALES_NAMES if name in all_sales]
        valid_dist_names = [name for name in DISTRIBUTOR_SALES_NAMES if name in all_sales]
        
        menu_options = SPECIAL_OPTS + sorted(all_sales)

        def on_selection_change():
            current = st.session_state.overview_sales_select
            previous = st.session_state.overview_sales_prev
            
            added = [item for item in current if item not in previous]
            new_selection = current
            
            if added:
                new_item = added[-1]
                if new_item in SPECIAL_OPTS:
                    new_selection = [new_item]
                else:
                    new_selection = [item for item in current if item not in SPECIAL_OPTS]
            
            st.session_state.overview_sales_select = new_selection
            st.session_state.overview_sales_prev = new_selection

        with col2:
            st.multiselect(
                "ğŸ‘¥ é¸æ“‡æŸ¥çœ‹å°è±¡",
                options=menu_options,
                key="overview_sales_select", 
                on_change=on_selection_change 
            )

        selected_options = st.session_state.overview_sales_select
        
        final_target_set = set()
        if OPT_ALL in selected_options:
            final_target_set.update(all_sales)
        else:
            if OPT_DIRECT in selected_options:
                final_target_set.update(valid_direct_names)
            if OPT_DIST in selected_options:
                final_target_set.update(valid_dist_names)
            
            for opt in selected_options:
                if opt not in SPECIAL_OPTS:
                    final_target_set.add(opt)
        
        target_users = sorted(list(final_target_set))
            
    else:
        with col2:
            st.text_input("ğŸ‘¤ æŸ¥çœ‹å°è±¡", value=current_user_name, disabled=True)
        target_users = [current_user_name]

    if not target_users:
        if user_role == "manager":
            st.info("è«‹é¸æ“‡äººå“¡æˆ–ç¾¤çµ„ (é è¨­ä¸é¡¯ç¤ºï¼Œè«‹æ‰‹å‹•é¸æ“‡)ã€‚")
        else:
            st.error("æ‰¾ä¸åˆ°æ‚¨çš„è³‡æ–™è¡¨ï¼Œè«‹è¯ç¹«ç®¡ç†å“¡ã€‚")
        # é€™è£¡ä¸ returnï¼Œç¹¼çºŒå¾€ä¸‹èµ°ï¼Œè®“æ—¥æœŸé©—è­‰é‚è¼¯ä¹Ÿèƒ½é¡¯ç¤ºè­¦å‘Š
        # ä½†å¦‚æœæ˜¯ç©ºçš„ï¼Œä¸‹æ–¹çš„è³‡æ–™æŸ¥è©¢è‡ªç„¶ä¸æœƒè·‘å‡ºçµæœ

    # ã€èª¿æ•´é †åºã€‘æœ€å¾Œå†é©—è­‰æ—¥æœŸï¼Œè‹¥ä¸å®Œæ•´å‰‡æš«åœï¼Œä¸å½±éŸ¿ä¸Šæ–¹ UI
    if isinstance(date_range, tuple) and len(date_range) == 2:
        start_date, end_date = date_range
    else:
        st.warning("è«‹é¸æ“‡å®Œæ•´çš„èµ·å§‹èˆ‡çµæŸæ—¥æœŸ")
        return
        
    # è‹¥äººå“¡ç‚ºç©ºï¼Œåœ¨é€™è£¡é˜»æ“‹
    if not target_users:
        return

    # ã€è³‡å®‰å¼·åŒ–ã€‘æ¬Šé™äºŒç¢º (Permission Double-Check)
    # åœ¨é–‹å§‹æŸ¥è©¢è³‡æ–™å‰ï¼Œå†æ¬¡é©—è­‰æ¬Šé™ï¼Œé˜²æ­¢ Session ç«„æ”¹æˆ–é‚è¼¯æ¼æ´
    if not is_manager:
        # éç®¡ç†å“¡ï¼Œå¿…é ˆç¢ºä¿æŸ¥è©¢å°è±¡åªæœ‰è‡ªå·±
        invalid_targets = [u for u in target_users if u != real_name]
        if invalid_targets:
            st.error("â›” å®‰å…¨è­¦å‘Šï¼šæ¬Šé™ç•°å¸¸ï¼Œæ‚¨ç„¡æ³•æŸ¥çœ‹å…¶ä»–äººçš„è³‡æ–™ã€‚")
            logging.warning(f"SECURITY ALERT: User {real_name} tried to access {invalid_targets}")
            return

    st.markdown("---")
    
    # === 3. è®€å–èˆ‡é¡¯ç¤º (æ™ºæ…§é€Ÿç‡é™åˆ¶ç‰ˆ) ===
    all_data = []
    
    MAX_USERS = 30
    if len(target_users) > MAX_USERS:
        st.error(f"âš ï¸ ä¸€æ¬¡æœ€å¤šæŸ¥è©¢ {MAX_USERS} ä½æ¥­å‹™å“¡ï¼Œè«‹ç¸®å°ç¯„åœ")
        return
    
    estimated_time = len(target_users) * rate_limiter.current_delay
    st.info(f"â±ï¸ æ­£åœ¨è®€å– {len(target_users)} ä½æ¥­å‹™å“¡è³‡æ–™ (é è¨ˆéœ€æ™‚ {estimated_time:.1f} ç§’)")
    
    # é˜²æ­¢é‡è¤‡æŸ¥è©¢çš„æ©Ÿåˆ¶
    query_key = f"{start_date}_{end_date}_{'_'.join(sorted(target_users))}"
    
    if "last_query_key" not in st.session_state:
        st.session_state.last_query_key = ""
    if "last_query_data" not in st.session_state:
        st.session_state.last_query_data = None
    
    # å¦‚æœæŸ¥è©¢æ¢ä»¶ç›¸åŒï¼Œç›´æ¥ä½¿ç”¨å¿«å–çµæœ
    if st.session_state.last_query_key == query_key and st.session_state.last_query_data is not None:
        st.success("âœ… ä½¿ç”¨å¿«å–è³‡æ–™ (ç„¡éœ€é‡æ–°æŸ¥è©¢)")
        final_df = st.session_state.last_query_data
    else:
        # åŸ·è¡Œæ–°æŸ¥è©¢
        with st.spinner(f"å½™æ•´ä¸­..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            failed_users = []
            
            for idx, user_name in enumerate(target_users):
                status_text.text(f"æ­£åœ¨è®€å–: {user_name} ({idx+1}/{len(target_users)})")
                ws = ws_map.get(user_name)
                
                if ws:
                    try:
                        rate_limiter.wait()
                        
                        df = load_data_from_sheet(ws, start_date, end_date)
                        if not df.empty:
                            df.insert(0, "æ¥­å‹™å“¡", user_name)
                            all_data.append(df)
                    
                    except APIError as e:
                        if "429" in str(e):
                            failed_users.append(user_name)
                            st.warning(f"âš ï¸ {user_name} è®€å–å¤±æ•— (API è¶…è¼‰)ï¼Œè«‹ç¨å¾Œé‡è©¦")
                        else:
                            failed_users.append(user_name)
                    except Exception as e:
                        failed_users.append(user_name)
                
                progress_bar.progress((idx + 1) / len(target_users))
            
            status_text.empty()
            progress_bar.empty()
            
            if failed_users:
                st.error(f"âŒ ä»¥ä¸‹ {len(failed_users)} ä½æ¥­å‹™å“¡è³‡æ–™è®€å–å¤±æ•—: {', '.join(failed_users)}")

        if not all_data:
            st.info("ğŸ” æ‰€é¸å€é–“å…§ç„¡è³‡æ–™ã€‚")
            return

        final_df = pd.concat(all_data, ignore_index=True)
        
        # å„²å­˜åˆ°å¿«å–
        st.session_state.last_query_key = query_key
        st.session_state.last_query_data = final_df
    
    # çµ±è¨ˆæ‘˜è¦
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆæ‘˜è¦ ({start_date} ~ {end_date})")
    m1, m2, m3 = st.columns(3)
    m1.metric("ç¸½å¡«å¯«ç­†æ•¸", len(final_df))
    m2.metric("åƒèˆ‡æ¥­å‹™äººæ•¸", len(final_df["æ¥­å‹™å“¡"].unique()))
    
    # ã€ä¿®æ­£ã€‘æ’é™¤ "-" èˆ‡ç©ºç™½çš„å®¢æˆ¶åç¨±ï¼Œåªè¨ˆç®—æœ‰æ•ˆå®¢æˆ¶
    unique_clients = final_df["å®¢æˆ¶åç¨±"].unique()
    valid_clients = [c for c in unique_clients if str(c).strip() not in ["-", ""]]
    m3.metric("æ‹œè¨ªå®¢æˆ¶æ•¸", len(valid_clients))

    # è©³ç´°è¡¨æ ¼
    st.subheader("ğŸ“ è©³ç´°åˆ—è¡¨")
    
    MAX_DISPLAY_ROWS = 1000
    if len(final_df) > MAX_DISPLAY_ROWS:
        st.warning(f"âš ï¸ è³‡æ–™éå¤šï¼Œåƒ…é¡¯ç¤ºå‰ {MAX_DISPLAY_ROWS} ç­† (ä¸‹è¼‰ CSV å¯å–å¾—å®Œæ•´è³‡æ–™)")
        display_df = final_df.head(MAX_DISPLAY_ROWS)
    else:
        display_df = final_df
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "æ—¥æœŸ": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD"),
            "æœ€å¾Œæ›´æ–°æ™‚é–“": st.column_config.TextColumn("æ›´æ–°æ™‚é–“", width="small")
        }
    )

    # åŒ¯å‡º CSV
    fname = f"æ¥­å‹™æ—¥å ±å½™æ•´_{start_date}_{end_date}.csv"
    
    export_df = final_df.copy()
    export_df = export_df.applymap(sanitize_csv_field)
    
    csv = export_df.to_csv(index=False).encode('utf-8-sig')
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰ CSV å ±è¡¨",
        data=csv,
        file_name=fname,
        mime="text/csv",
        type="primary"
    )
    
    # æ‰‹å‹•æ¸…é™¤å¿«å–æŒ‰éˆ•
    st.markdown("---")
    if st.button("ğŸ”„ é‡æ–°è¼‰å…¥é é¢"):
        st.session_state.last_query_key = ""
        st.session_state.last_query_data = None
        st.success("âœ… å¿«å–å·²æ¸…é™¤ï¼Œæ­£åœ¨é‡æ–°è¼‰å…¥...")
        time.sleep(1)
        st.rerun()